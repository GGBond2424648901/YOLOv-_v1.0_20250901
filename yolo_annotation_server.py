#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLOvæ™ºèƒ½æ ‡æ³¨å·¥å…· - åç«¯APIæœåŠ¡
æ”¯æŒYOLOv5/YOLOv8æ¨¡å‹çš„åŠ è½½å’Œæ¨ç†ï¼Œæä¾›RESTful APIæ¥å£
"""

import os
import io
import json
import uuid
import time
import shutil
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

import cv2
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import torch
import torchvision.transforms as transforms
from flask import Flask, request, jsonify, send_file, render_template_string
from flask_cors import CORS
from werkzeug.utils import secure_filename
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# é…ç½®
UPLOAD_FOLDER = 'uploads'
MODELS_FOLDER = 'models'
RESULTS_FOLDER = 'results'
ALLOWED_EXTENSIONS = {
    'model': {'pt'},
    'image': {'png', 'jpg', 'jpeg', 'gif', 'bmp', 'tiff'},
    'video': {'mp4', 'avi', 'mov', 'mkv', 'flv', 'wmv'}
}

# åˆ›å»ºå¿…è¦çš„æ–‡ä»¶å¤¹
for folder in [UPLOAD_FOLDER, MODELS_FOLDER, RESULTS_FOLDER]:
    os.makedirs(folder, exist_ok=True)

# å…¨å±€å˜é‡
current_model = None
model_info = {}
session_data = {}

class YOLOModel:
    """YOLOæ¨¡å‹åŒ…è£…å™¨"""
    
    def __init__(self, model_path: str):
        self.model_path = model_path
        self.model = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.class_names = []
        self.model_type = self.detect_model_type(model_path)
        self.load_model()
    
    def detect_model_type(self, model_path: str) -> str:
        """æ£€æµ‹æ¨¡å‹ç±»å‹ï¼ˆYOLOv5æˆ–YOLOv8ï¼‰"""
        try:
            checkpoint = torch.load(model_path, map_location='cpu')
            if 'model' in checkpoint:
                # YOLOv5é£æ ¼
                return 'yolov5'
            else:
                # YOLOv8é£æ ¼
                return 'yolov8'
        except Exception as e:
            logger.warning(f"æ— æ³•ç¡®å®šæ¨¡å‹ç±»å‹ï¼Œé»˜è®¤ä½¿ç”¨YOLOv5: {e}")
            return 'yolov5'
    
    def load_model(self):
        """åŠ è½½YOLOæ¨¡å‹"""
        try:
            # ä¼˜å…ˆå°è¯•ä½¿ç”¨ultralytics (YOLOv8)
            try:
                from ultralytics import YOLO
                self.model = YOLO(self.model_path)
                self.class_names = list(self.model.names.values())
                self.model_type = 'yolov8'
                logger.info(f"æˆåŠŸåŠ è½½YOLOv8æ¨¡å‹: {self.model_path}")
                return
            except Exception as e:
                logger.warning(f"YOLOv8åŠ è½½å¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•: {e}")
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šç›´æ¥åŠ è½½æƒé‡
            self.load_weights_directly()
                
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œåˆ›å»ºä¸€ä¸ªè™šæ‹Ÿæ¨¡å‹ç”¨äºæ¼”ç¤º
            self.create_dummy_model()
    
    def create_dummy_model(self):
        """åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ç”¨äºæ¼”ç¤º"""
        logger.warning("åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ç”¨äºæ¼”ç¤º")
        self.model = None
        self.class_names = self.get_coco_classes()
        self.model_type = 'dummy'
    
    def load_weights_directly(self):
        """ç›´æ¥åŠ è½½æƒé‡æ–‡ä»¶"""
        try:
            logger.info("å°è¯•ç›´æ¥åŠ è½½æƒé‡æ–‡ä»¶...")
            checkpoint = torch.load(self.model_path, map_location='cpu')
            
            # æ£€æŸ¥ä¸åŒçš„æƒé‡æ–‡ä»¶æ ¼å¼
            if 'model' in checkpoint:
                # YOLOv5æ ¼å¼
                self.model = checkpoint['model'].float().eval()
                if hasattr(self.model, 'names'):
                    self.class_names = list(self.model.names.values()) if isinstance(self.model.names, dict) else self.model.names
                else:
                    self.class_names = self.get_coco_classes()
                self.model_type = 'yolov5'
            elif isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
                # å…¶ä»–æ ¼å¼
                logger.warning("æ£€æµ‹åˆ°state_dictæ ¼å¼ï¼Œä½¿ç”¨COCOç±»åˆ«")
                self.class_names = self.get_coco_classes()
                self.model_type = 'custom'
            else:
                # æœªçŸ¥æ ¼å¼ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«
                logger.warning("æœªçŸ¥æ¨¡å‹æ ¼å¼ï¼Œä½¿ç”¨COCOç±»åˆ«")
                self.class_names = self.get_coco_classes()
                self.model_type = 'unknown'
                
            logger.info(f"ç›´æ¥æƒé‡åŠ è½½æˆåŠŸï¼Œç±»åˆ«æ•°: {len(self.class_names)}")
            
        except Exception as e:
            logger.error(f"ç›´æ¥æƒé‡åŠ è½½å¤±è´¥: {e}")
            # ä¸å†æŠ›å‡ºå¼‚å¸¸ï¼Œè®©create_dummy_modelå¤„ç†
            raise
    
    def get_coco_classes(self) -> List[str]:
        """è·å–COCOæ•°æ®é›†çš„ç±»åˆ«åç§°"""
        return [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',
            'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',
            'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
            'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',
            'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',
            'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet',
            'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',
            'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',
            'hair drier', 'toothbrush'
        ]
    
    def predict(self, image: np.ndarray, conf_threshold: float = 0.5, 
                iou_threshold: float = 0.45, img_size: int = 640) -> List[Dict]:
        """å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹"""
        try:
            # å¦‚æœæ˜¯è™šæ‹Ÿæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡æ‹Ÿç»“æœ
            if self.model_type == 'dummy' or self.model is None:
                return self.generate_dummy_predictions(image.shape, conf_threshold)
            
            # é¢„å¤„ç†å›¾åƒ
            original_shape = image.shape[:2]
            
            if self.model_type == 'yolov8' and hasattr(self.model, 'predict'):
                # YOLOv8é¢„æµ‹
                results = self.model.predict(image, conf=conf_threshold, 
                                           iou=iou_threshold, imgsz=img_size)
                return self.parse_yolov8_results(results[0], original_shape)
            else:
                # YOLOv5é¢„æµ‹æˆ–å…¶ä»–ç±»å‹
                if hasattr(self.model, '__call__'):
                    results = self.model(image, size=img_size)
                    return self.parse_yolov5_results(results, conf_threshold, 
                                                   iou_threshold, original_shape)
                else:
                    # å¦‚æœæ¨¡å‹ä¸èƒ½æ­£å¸¸è°ƒç”¨ï¼Œè¿”å›è™šæ‹Ÿç»“æœ
                    return self.generate_dummy_predictions(image.shape, conf_threshold)
                
        except Exception as e:
            logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
            # å‡ºé”™æ—¶ä¹Ÿè¿”å›è™šæ‹Ÿç»“æœï¼Œè®©ç”¨æˆ·èƒ½å¤Ÿä½“éªŒåŠŸèƒ½
            return self.generate_dummy_predictions(image.shape, conf_threshold)
    
    def generate_dummy_predictions(self, image_shape, conf_threshold: float) -> List[Dict]:
        """ç”Ÿæˆè™šæ‹Ÿé¢„æµ‹ç»“æœç”¨äºæ¼”ç¤º"""
        import random
        
        height, width = image_shape[:2]
        predictions = []
        
        # ç”Ÿæˆ2-5ä¸ªè™šæ‹Ÿæ£€æµ‹ç»“æœ
        num_objects = random.randint(2, 5)
        common_classes = ['person', 'car', 'bicycle', 'dog', 'cat', 'bus', 'truck']
        
        for i in range(num_objects):
            # éšæœºé€‰æ‹©ç±»åˆ«
            class_name = random.choice(common_classes)
            class_id = self.class_names.index(class_name) if class_name in self.class_names else 0
            
            # ç”Ÿæˆéšæœºè¾¹ç•Œæ¡†
            x1 = random.randint(0, width // 2)
            y1 = random.randint(0, height // 2)
            w = random.randint(50, min(200, width - x1))
            h = random.randint(50, min(200, height - y1))
            
            # ç”Ÿæˆç½®ä¿¡åº¦
            confidence = conf_threshold + random.random() * (0.95 - conf_threshold)
            
            prediction = {
                'id': str(uuid.uuid4()),
                'class_id': class_id,
                'class_name': class_name,
                'confidence': confidence,
                'bbox': {
                    'x1': float(x1),
                    'y1': float(y1),
                    'x2': float(x1 + w),
                    'y2': float(y1 + h),
                    'width': float(w),
                    'height': float(h)
                }
            }
            predictions.append(prediction)
        
        logger.info(f"ç”Ÿæˆäº†{len(predictions)}ä¸ªè™šæ‹Ÿæ£€æµ‹ç»“æœ")
        return predictions
    
    def parse_yolov8_results(self, result, original_shape: Tuple[int, int]) -> List[Dict]:
        """è§£æYOLOv8ç»“æœ"""
        detections = []
        
        if result.boxes is not None:
            boxes = result.boxes.xyxy.cpu().numpy()
            confidences = result.boxes.conf.cpu().numpy()
            class_ids = result.boxes.cls.cpu().numpy().astype(int)
            
            for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):
                x1, y1, x2, y2 = box
                
                detection = {
                    'id': str(uuid.uuid4()),
                    'class_id': int(class_id),
                    'class_name': self.class_names[class_id] if class_id < len(self.class_names) else f'class_{class_id}',
                    'confidence': float(conf),
                    'bbox': {
                        'x1': float(x1),
                        'y1': float(y1),
                        'x2': float(x2), 
                        'y2': float(y2),
                        'width': float(x2 - x1),
                        'height': float(y2 - y1)
                    }
                }
                detections.append(detection)
        
        return detections
    
    def parse_yolov5_results(self, results, conf_threshold: float, 
                           iou_threshold: float, original_shape: Tuple[int, int]) -> List[Dict]:
        """è§£æYOLOv5ç»“æœ"""
        detections = []
        
        # åº”ç”¨NMS
        pred = results.pred[0]
        if pred is not None and len(pred) > 0:
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
            pred = pred[pred[:, 4] >= conf_threshold]
            
            if len(pred) > 0:
                # åº”ç”¨NMS
                keep = torch.ops.torchvision.nms(pred[:, :4], pred[:, 4], iou_threshold)
                pred = pred[keep]
                
                for detection in pred:
                    x1, y1, x2, y2, conf, class_id = detection[:6]
                    class_id = int(class_id)
                    
                    detection_dict = {
                        'id': str(uuid.uuid4()),
                        'class_id': class_id,
                        'class_name': self.class_names[class_id] if class_id < len(self.class_names) else f'class_{class_id}',
                        'confidence': float(conf),
                        'bbox': {
                            'x1': float(x1),
                            'y1': float(y1),
                            'x2': float(x2),
                            'y2': float(y2), 
                            'width': float(x2 - x1),
                            'height': float(y2 - y1)
                        }
                    }
                    detections.append(detection_dict)
        
        return detections

def allowed_file(filename: str, file_type: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦å…è®¸"""
    return '.' in filename and \
           filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS[file_type]

def generate_session_id() -> str:
    """ç”Ÿæˆä¼šè¯ID"""
    return str(uuid.uuid4())

@app.route('/')
def index():
    """è¿”å›ä¸»é¡µé¢"""
    with open('yolo_annotation_tool.html', 'r', encoding='utf-8') as f:
        return f.read()

@app.route('/uploads/<filename>')
def uploaded_file(filename):
    """æä¾›ä¸Šä¼ æ–‡ä»¶çš„è®¿é—®"""
    return send_file(os.path.join(UPLOAD_FOLDER, filename))

@app.route('/api/upload_model', methods=['POST'])
def upload_model():
    """ä¸Šä¼ æ¨¡å‹æ–‡ä»¶"""
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        if not allowed_file(file.filename, 'model'):
            return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼ .ptæ–‡ä»¶'}), 400
        
        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        filepath = os.path.join(MODELS_FOLDER, filename)
        file.save(filepath)
        
        # åŠ è½½æ¨¡å‹
        global current_model, model_info
        logger.info(f"å¼€å§‹åŠ è½½æ¨¡å‹: {filename}")
        
        try:
            current_model = YOLOModel(filepath)
            
            model_info = {
                'filename': filename,
                'filepath': filepath,
                'size': os.path.getsize(filepath),
                'classes': current_model.class_names,
                'num_classes': len(current_model.class_names),
                'model_type': current_model.model_type,
                'device': str(current_model.device),
                'loaded_at': datetime.now().isoformat()
            }
            
            logger.info(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {current_model.model_type}, ç±»åˆ«æ•°: {len(current_model.class_names)}")
            
            return jsonify({
                'message': f'æ¨¡å‹ä¸Šä¼ æˆåŠŸ (ç±»å‹: {current_model.model_type})',
                'model_info': model_info
            })
            
        except Exception as model_error:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {model_error}")
            # åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
            if os.path.exists(filepath):
                os.remove(filepath)
            return jsonify({'error': f'æ¨¡å‹åŠ è½½å¤±è´¥: {str(model_error)}'}), 500
        
    except Exception as e:
        logger.error(f"æ¨¡å‹ä¸Šä¼ å¤±è´¥: {e}")
        return jsonify({'error': f'æ¨¡å‹ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500

@app.route('/api/model_info', methods=['GET'])
def get_model_info():
    """è·å–å½“å‰æ¨¡å‹ä¿¡æ¯"""
    if current_model is None:
        return jsonify({'error': 'æ²¡æœ‰åŠ è½½çš„æ¨¡å‹'}), 400
    
    return jsonify(model_info)

@app.route('/api/list_models', methods=['GET'])
def list_models():
    """åˆ—å‡ºmodelsç›®å½•ä¸­çš„æ‰€æœ‰æ¨¡å‹æ–‡ä»¶"""
    try:
        model_files = []
        if os.path.exists(MODELS_FOLDER):
            for filename in os.listdir(MODELS_FOLDER):
                if filename.endswith('.pt'):
                    filepath = os.path.join(MODELS_FOLDER, filename)
                    file_stat = os.stat(filepath)
                    model_files.append({
                        'filename': filename,
                        'size': file_stat.st_size,
                        'size_mb': f"{file_stat.st_size / 1024 / 1024:.1f} MB",
                        'modified': datetime.fromtimestamp(file_stat.st_mtime).isoformat()
                    })
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        model_files.sort(key=lambda x: x['modified'], reverse=True)
        
        return jsonify({
            'models': model_files,
            'count': len(model_files)
        })
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': f'åˆ—å‡ºæ¨¡å‹æ–‡ä»¶å¤±è´¥: {str(e)}'}), 500

@app.route('/api/load_existing_model', methods=['POST'])
def load_existing_model():
    """åŠ è½½å·²å­˜åœ¨çš„æ¨¡å‹æ–‡ä»¶"""
    try:
        data = request.get_json()
        filename = data.get('filename')
        
        if not filename:
            return jsonify({'error': 'è¯·æä¾›æ¨¡å‹æ–‡ä»¶å'}), 400
        
        filepath = os.path.join(MODELS_FOLDER, filename)
        if not os.path.exists(filepath):
            return jsonify({'error': 'æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        if not filename.endswith('.pt'):
            return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'}), 400
        
        # åŠ è½½æ¨¡å‹
        global current_model, model_info
        logger.info(f"å¼€å§‹åŠ è½½ç°æœ‰æ¨¡å‹: {filename}")
        
        try:
            current_model = YOLOModel(filepath)
            
            model_info = {
                'filename': filename,
                'filepath': filepath,
                'size': os.path.getsize(filepath),
                'classes': current_model.class_names,
                'num_classes': len(current_model.class_names),
                'model_type': current_model.model_type,
                'device': str(current_model.device),
                'loaded_at': datetime.now().isoformat()
            }
            
            logger.info(f"ç°æœ‰æ¨¡å‹åŠ è½½æˆåŠŸ: {current_model.model_type}, ç±»åˆ«æ•°: {len(current_model.class_names)}")
            
            return jsonify({
                'message': f'æ¨¡å‹åŠ è½½æˆåŠŸ (ç±»å‹: {current_model.model_type})',
                'model_info': model_info
            })
            
        except Exception as model_error:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {model_error}")
            return jsonify({'error': f'æ¨¡å‹åŠ è½½å¤±è´¥: {str(model_error)}'}), 500
            
    except Exception as e:
        logger.error(f"åŠ è½½ç°æœ‰æ¨¡å‹å¤±è´¥: {e}")
        return jsonify({'error': f'åŠ è½½ç°æœ‰æ¨¡å‹å¤±è´¥: {str(e)}'}), 500

@app.route('/api/upload_media', methods=['POST'])
def upload_media():
    """ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘æ–‡ä»¶"""
    try:
        if 'files' not in request.files:
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
        
        files = request.files.getlist('files')
        session_id = generate_session_id()
        
        uploaded_files = []
        
        for file in files:
            if file.filename == '':
                continue
                
            # æ£€æŸ¥æ–‡ä»¶ç±»å‹
            is_image = allowed_file(file.filename, 'image')
            is_video = allowed_file(file.filename, 'video')
            
            if not (is_image or is_video):
                continue
            
            # ä¿å­˜æ–‡ä»¶
            filename = secure_filename(file.filename)
            unique_filename = f"{session_id}_{filename}"
            filepath = os.path.join(UPLOAD_FOLDER, unique_filename)
            file.save(filepath)
            
            file_info = {
                'filename': filename,
                'unique_filename': unique_filename,
                'filepath': filepath,
                'size': os.path.getsize(filepath),
                'type': 'image' if is_image else 'video',
                'session_id': session_id
            }
            
            uploaded_files.append(file_info)
        
        # ä¿å­˜ä¼šè¯æ•°æ®
        session_data[session_id] = {
            'files': uploaded_files,
            'predictions': {},  # åˆå§‹åŒ–predictionså­—æ®µ
            'created_at': datetime.now().isoformat()
        }
        
        return jsonify({
            'message': f'æˆåŠŸä¸Šä¼  {len(uploaded_files)} ä¸ªæ–‡ä»¶',
            'session_id': session_id,
            'files': uploaded_files
        })
        
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        return jsonify({'error': f'æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}'}), 500

@app.route('/api/predict', methods=['POST'])
def predict():
    """å¯¹å›¾ç‰‡è¿›è¡Œé¢„æµ‹"""
    try:
        if current_model is None:
            return jsonify({'error': 'è¯·å…ˆä¸Šä¼ å¹¶åŠ è½½æ¨¡å‹'}), 400
        
        data = request.get_json()
        if not data:
            return jsonify({'error': 'ç¼ºå°‘è¯·æ±‚æ•°æ®'}), 400
        
        session_id = data.get('session_id')
        filename = data.get('filename')
        conf_threshold = float(data.get('conf_threshold', 0.5))
        iou_threshold = float(data.get('iou_threshold', 0.45))
        img_size = int(data.get('img_size', 640))
        selected_classes = data.get('selected_classes', [])  # æ–°å¢ï¼šé€‰æ‹©çš„ç±»åˆ«IDåˆ—è¡¨
        
        if not session_id or not filename:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        # æŸ¥æ‰¾æ–‡ä»¶
        if session_id not in session_data:
            return jsonify({'error': 'ä¼šè¯ä¸å­˜åœ¨'}), 404
        
        file_info = None
        for file_data in session_data[session_id]['files']:
            if file_data['unique_filename'] == filename:
                file_info = file_data
                break
        
        if not file_info:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        if file_info['type'] != 'image':
            return jsonify({'error': 'åªæ”¯æŒå›¾ç‰‡é¢„æµ‹'}), 400
        
        # è¯»å–å›¾ç‰‡
        image_path = file_info['filepath']
        image = cv2.imread(image_path)
        if image is None:
            return jsonify({'error': 'æ— æ³•è¯»å–å›¾ç‰‡'}), 500
        
        # è½¬æ¢ä¸ºRGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # è¿›è¡Œé¢„æµ‹
        detections = current_model.predict(
            image_rgb, conf_threshold, iou_threshold, img_size
        )
        
        # æ ¹æ®é€‰æ‹©çš„ç±»åˆ«è¿‡æ»¤æ£€æµ‹ç»“æœ
        if selected_classes:
            detections = [det for det in detections if det.get('class_id') in selected_classes]
        
        # ä¿å­˜ç»“æœ
        result_data = {
            'session_id': session_id,
            'filename': filename,
            'image_shape': image.shape,
            'detections': detections,
            'parameters': {
                'conf_threshold': conf_threshold,
                'iou_threshold': iou_threshold,
                'img_size': img_size
            },
            'timestamp': datetime.now().isoformat()
        }
        
        # ä¿å­˜åˆ°ä¼šè¯æ•°æ®
        if 'predictions' not in session_data[session_id]:
            session_data[session_id]['predictions'] = {}
        session_data[session_id]['predictions'][filename] = result_data
        
        return jsonify({
            'message': f'æ£€æµ‹å®Œæˆï¼Œå‘ç° {len(detections)} ä¸ªç›®æ ‡',
            'detections': detections,
            'image_shape': image.shape
        })
        
    except Exception as e:
        logger.error(f"é¢„æµ‹å¤±è´¥: {e}")
        return jsonify({'error': f'é¢„æµ‹å¤±è´¥: {str(e)}'}), 500

@app.route('/api/export_annotations', methods=['POST'])
def export_annotations():
    """å¯¼å‡ºæ ‡æ³¨æ•°æ®"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'ç¼ºå°‘è¯·æ±‚æ•°æ®'}), 400
        
        session_id = data.get('session_id')
        filename = data.get('filename')
        format_type = data.get('format', 'yolo_json')
        annotations = data.get('annotations', [])
        
        if not session_id or not filename:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        # ç”Ÿæˆå¯¼å‡ºæ•°æ®
        export_data = generate_export_data(annotations, format_type, session_id, filename)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        export_filename = f"{session_id}_{filename}_{format_type}.{get_export_extension(format_type)}"
        export_path = os.path.join(RESULTS_FOLDER, export_filename)
        
        with open(export_path, 'w', encoding='utf-8') as f:
            if format_type.endswith('json'):
                json.dump(export_data, f, indent=2, ensure_ascii=False)
            else:
                f.write(export_data)
        
        return send_file(export_path, as_attachment=True, download_name=export_filename)
        
    except Exception as e:
        logger.error(f"å¯¼å‡ºå¤±è´¥: {e}")
        return jsonify({'error': f'å¯¼å‡ºå¤±è´¥: {str(e)}'}), 500

@app.route('/api/batch_predict', methods=['POST'])
def batch_predict():
    """æ‰¹é‡é¢„æµ‹"""
    try:
        if current_model is None:
            return jsonify({'error': 'è¯·å…ˆä¸Šä¼ å¹¶åŠ è½½æ¨¡å‹'}), 400
        
        data = request.get_json()
        session_id = data.get('session_id')
        conf_threshold = float(data.get('conf_threshold', 0.5))
        iou_threshold = float(data.get('iou_threshold', 0.45))
        img_size = int(data.get('img_size', 640))
        selected_classes = data.get('selected_classes', [])  # æ–°å¢ï¼šé€‰æ‹©çš„ç±»åˆ«IDåˆ—è¡¨
        
        if not session_id or session_id not in session_data:
            return jsonify({'error': 'ä¼šè¯ä¸å­˜åœ¨'}), 404
        
        files = session_data[session_id]['files']
        image_files = [f for f in files if f['type'] == 'image']
        
        if not image_files:
            return jsonify({'error': 'æ²¡æœ‰å¯å¤„ç†çš„å›¾ç‰‡æ–‡ä»¶'}), 400
        
        results = []
        
        for file_info in image_files:
            try:
                # è¯»å–å›¾ç‰‡
                image = cv2.imread(file_info['filepath'])
                if image is None:
                    continue
                
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # è¿›è¡Œé¢„æµ‹
                detections = current_model.predict(
                    image_rgb, conf_threshold, iou_threshold, img_size
                )
                
                # æ ¹æ®é€‰æ‹©çš„ç±»åˆ«è¿‡æ»¤æ£€æµ‹ç»“æœ
                if selected_classes:
                    detections = [det for det in detections if det.get('class_id') in selected_classes]
                
                result = {
                    'filename': file_info['filename'],
                    'unique_filename': file_info['unique_filename'],
                    'detections': detections,
                    'count': len(detections)
                }
                
                results.append(result)
                
                # ä¿å­˜åˆ°ä¼šè¯æ•°æ®
                if 'predictions' not in session_data[session_id]:
                    session_data[session_id]['predictions'] = {}
                
                session_data[session_id]['predictions'][file_info['unique_filename']] = {
                    'session_id': session_id,
                    'filename': file_info['unique_filename'],
                    'image_shape': image.shape,
                    'detections': detections,
                    'parameters': {
                        'conf_threshold': conf_threshold,
                        'iou_threshold': iou_threshold,
                        'img_size': img_size
                    },
                    'timestamp': datetime.now().isoformat()
                }
                
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {file_info['filename']} å¤±è´¥: {e}")
                continue
        
        return jsonify({
            'message': f'æ‰¹é‡å¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªæ–‡ä»¶',
            'results': results
        })
        
    except Exception as e:
        logger.error(f"æ‰¹é‡é¢„æµ‹å¤±è´¥: {e}")
        return jsonify({'error': f'æ‰¹é‡é¢„æµ‹å¤±è´¥: {str(e)}'}), 500

def generate_export_data(annotations: List[Dict], format_type: str, 
                        session_id: str, filename: str) -> Any:
    """ç”Ÿæˆä¸åŒæ ¼å¼çš„å¯¼å‡ºæ•°æ®"""
    
    if format_type == 'yolo_json':
        return {
            'version': '1.0',
            'created': datetime.now().isoformat(),
            'session_id': session_id,
            'filename': filename,
            'classes': current_model.class_names if current_model else [],
            'annotations': annotations
        }
    
    elif format_type == 'coco_json':
        categories = []
        if current_model:
            categories = [
                {'id': i, 'name': name, 'supercategory': 'object'}
                for i, name in enumerate(current_model.class_names)
            ]
        
        coco_annotations = []
        for i, ann in enumerate(annotations):
            bbox = ann.get('bbox', {})
            coco_annotations.append({
                'id': i,
                'image_id': 1,
                'category_id': ann.get('class_id', 0),
                'bbox': [
                    bbox.get('x1', 0),
                    bbox.get('y1', 0),
                    bbox.get('width', 0),
                    bbox.get('height', 0)
                ],
                'area': bbox.get('width', 0) * bbox.get('height', 0),
                'iscrowd': 0
            })
        
        return {
            'info': {
                'description': 'YOLOvæ™ºèƒ½æ ‡æ³¨å·¥å…·å¯¼å‡º',
                'version': '1.0',
                'date_created': datetime.now().isoformat()
            },
            'images': [{
                'id': 1,
                'file_name': filename,
                'width': 640,  # é»˜è®¤å€¼ï¼Œåº”è¯¥ä»å®é™…å›¾åƒè·å–
                'height': 640
            }],
            'categories': categories,
            'annotations': coco_annotations
        }
    
    elif format_type == 'yolo_txt':
        lines = []
        for ann in annotations:
            bbox = ann.get('bbox', {})
            # è½¬æ¢ä¸ºYOLOæ ¼å¼ (class_id x_center y_center width height)
            # è¿™é‡Œéœ€è¦å®é™…çš„å›¾åƒå°ºå¯¸æ¥æ­£ç¡®è½¬æ¢
            class_id = ann.get('class_id', 0)
            lines.append(f"{class_id} 0.5 0.5 0.1 0.1")  # å ä½ç¬¦å€¼
        
        return '\n'.join(lines)
    
    elif format_type == 'pascal_voc':
        # ç®€åŒ–çš„Pascal VOCæ ¼å¼
        objects = []
        for ann in annotations:
            bbox = ann.get('bbox', {})
            objects.append(f"""
    <object>
        <name>{ann.get('class_name', 'unknown')}</name>
        <pose>Unspecified</pose>
        <truncated>0</truncated>
        <difficult>0</difficult>
        <bndbox>
            <xmin>{int(bbox.get('x1', 0))}</xmin>
            <ymin>{int(bbox.get('y1', 0))}</ymin>
            <xmax>{int(bbox.get('x2', 0))}</xmax>
            <ymax>{int(bbox.get('y2', 0))}</ymax>
        </bndbox>
    </object>""")
        
        return f"""<?xml version="1.0" encoding="UTF-8"?>
<annotation>
    <filename>{filename}</filename>
    <size>
        <width>640</width>
        <height>640</height>
        <depth>3</depth>
    </size>
    {''.join(objects)}
</annotation>"""
    
    return {}

def get_export_extension(format_type: str) -> str:
    """è·å–å¯¼å‡ºæ ¼å¼çš„æ–‡ä»¶æ‰©å±•å"""
    extensions = {
        'yolo_json': 'json',
        'coco_json': 'json',
        'yolo_txt': 'txt',
        'pascal_voc': 'xml'
    }
    return extensions.get(format_type, 'json')

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'ok',
        'timestamp': datetime.now().isoformat(),
        'model_loaded': current_model is not None,
        'device': str(current_model.device) if current_model else 'none'
    })

@app.route('/api/export_dataset', methods=['POST'])
def export_dataset():
    """å¯¼å‡ºå®Œæ•´æ•°æ®é›†"""
    try:
        data = request.get_json()
        format_type = data.get('format', 'yolo_json')
        include_images = data.get('include_images', True)
        dataset_name = data.get('dataset_name', 'yolo_dataset')
        
        import zipfile
        import tempfile
        from datetime import datetime
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            dataset_dir = os.path.join(temp_dir, dataset_name)
            os.makedirs(dataset_dir, exist_ok=True)
            
            # åˆ›å»ºæ ‡å‡†YOLOæ•°æ®é›†ç»“æ„
            images_dir = os.path.join(dataset_dir, 'images')
            labels_dir = os.path.join(dataset_dir, 'labels')
            os.makedirs(images_dir, exist_ok=True)
            os.makedirs(labels_dir, exist_ok=True)
            
            exported_count = 0
            class_names = current_model.class_names if current_model else []
            
            # éå†æ‰€æœ‰ä¼šè¯æ•°æ®
            for session_id, session_info in session_data.items():
                predictions = session_info.get('predictions', {})
                files = session_info.get('files', [])
                
                for file_info in files:
                    if file_info['type'] != 'image':
                        continue
                        
                    filename = file_info['unique_filename']
                    filepath = file_info['filepath']
                    
                    if filename in predictions and os.path.exists(filepath):
                        prediction_data = predictions[filename]
                        detections = prediction_data.get('detections', [])
                        
                        if detections:  # åªå¯¼å‡ºæœ‰æ ‡æ³¨çš„å›¾ç‰‡
                            # å¤åˆ¶å›¾ç‰‡æ–‡ä»¶
                            if include_images:
                                original_name = file_info['filename']
                                image_dest = os.path.join(images_dir, original_name)
                                shutil.copy2(filepath, image_dest)
                            
                            # ç”Ÿæˆæ ‡æ³¨æ–‡ä»¶
                            base_name = os.path.splitext(file_info['filename'])[0]
                            
                            if format_type == 'yolo_txt':
                                # YOLOæ ¼å¼æ ‡æ³¨æ–‡ä»¶
                                label_file = os.path.join(labels_dir, f"{base_name}.txt")
                                with open(label_file, 'w') as f:
                                    image_shape = prediction_data.get('image_shape', [640, 640, 3])
                                    img_height, img_width = image_shape[:2]
                                    
                                    for det in detections:
                                        bbox = det.get('bbox', {})
                                        class_id = det.get('class_id', 0)
                                        
                                        # è½¬æ¢ä¸ºYOLOæ ¼å¼
                                        x_center = (bbox.get('x1', 0) + bbox.get('width', 0) / 2) / img_width
                                        y_center = (bbox.get('y1', 0) + bbox.get('height', 0) / 2) / img_height
                                        width = bbox.get('width', 0) / img_width
                                        height = bbox.get('height', 0) / img_height
                                        
                                        f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
                            
                            elif format_type == 'coco_json':
                                # COCOæ ¼å¼ï¼ˆæ¯ä¸ªå›¾ç‰‡ä¸€ä¸ªJSONæ–‡ä»¶ï¼‰
                                label_file = os.path.join(labels_dir, f"{base_name}.json")
                                coco_data = generate_coco_for_image(file_info, detections, class_names)
                                with open(label_file, 'w', encoding='utf-8') as f:
                                    json.dump(coco_data, f, indent=2, ensure_ascii=False)
                            
                            exported_count += 1
            
            # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
            if format_type == 'yolo_txt':
                # åˆ›å»ºYOLOé…ç½®æ–‡ä»¶
                config_file = os.path.join(dataset_dir, 'dataset.yaml')
                with open(config_file, 'w', encoding='utf-8') as f:
                    f.write(f"# YOLOvæ•°æ®é›†é…ç½®æ–‡ä»¶\n")
                    f.write(f"# ç”Ÿæˆæ—¶é—´: {datetime.now().isoformat()}\n\n")
                    f.write(f"train: images\n")
                    f.write(f"val: images\n\n")
                    f.write(f"nc: {len(class_names)}\n")
                    f.write(f"names: {class_names}\n")
            
            # åˆ›å»ºREADMEæ–‡ä»¶
            readme_file = os.path.join(dataset_dir, 'README.md')
            with open(readme_file, 'w', encoding='utf-8') as f:
                f.write(f"# YOLOvæ™ºèƒ½æ ‡æ³¨æ•°æ®é›†\n\n")
                f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"**å›¾ç‰‡æ•°é‡**: {exported_count}\n")
                f.write(f"**ç±»åˆ«æ•°é‡**: {len(class_names)}\n")
                f.write(f"**æ ‡æ³¨æ ¼å¼**: {format_type}\n\n")
                f.write(f"## æ•°æ®é›†ç»“æ„\n")
                f.write(f"```\n")
                f.write(f"{dataset_name}/\n")
                f.write(f"â”œâ”€â”€ images/          # å›¾ç‰‡æ–‡ä»¶\n")
                f.write(f"â”œâ”€â”€ labels/          # æ ‡æ³¨æ–‡ä»¶\n")
                f.write(f"â”œâ”€â”€ dataset.yaml     # YOLOé…ç½®æ–‡ä»¶\n")
                f.write(f"â””â”€â”€ README.md        # è¯´æ˜æ–‡æ¡£\n")
                f.write(f"```\n\n")
                f.write(f"## ç±»åˆ«åˆ—è¡¨\n")
                for i, name in enumerate(class_names):
                    f.write(f"{i}: {name}\n")
            
            # æ‰“åŒ…ä¸ºZIPæ–‡ä»¶
            zip_path = os.path.join(RESULTS_FOLDER, f"{dataset_name}_{format_type}_{int(time.time())}.zip")
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, dirs, files in os.walk(dataset_dir):
                    for file in files:
                        file_path = os.path.join(root, file)
                        arc_path = os.path.relpath(file_path, temp_dir)
                        zipf.write(file_path, arc_path)
            
            if exported_count == 0:
                return jsonify({'error': 'æ²¡æœ‰å¯å¯¼å‡ºçš„æ ‡æ³¨æ•°æ®'}), 400
            
            return send_file(zip_path, as_attachment=True, 
                           download_name=f"{dataset_name}_{format_type}.zip")
            
    except Exception as e:
        logger.error(f"å¯¼å‡ºæ•°æ®é›†å¤±è´¥: {e}")
        return jsonify({'error': f'å¯¼å‡ºæ•°æ®é›†å¤±è´¥: {str(e)}'}), 500

def generate_coco_for_image(file_info, detections, class_names):
    """ä¸ºå•ä¸ªå›¾ç‰‡ç”ŸæˆCOCOæ ¼å¼æ•°æ®"""
    return {
        'info': {
            'description': 'YOLOvæ™ºèƒ½æ ‡æ³¨å·¥å…·å¯¼å‡º',
            'version': '1.0',
            'date_created': datetime.now().isoformat()
        },
        'images': [{
            'id': 1,
            'file_name': file_info['filename'],
            'width': 640,  # é»˜è®¤å€¼
            'height': 640
        }],
        'categories': [
            {'id': i, 'name': name, 'supercategory': 'object'}
            for i, name in enumerate(class_names)
        ],
        'annotations': [
            {
                'id': i,
                'image_id': 1,
                'category_id': det.get('class_id', 0),
                'bbox': [
                    det.get('bbox', {}).get('x1', 0),
                    det.get('bbox', {}).get('y1', 0),
                    det.get('bbox', {}).get('width', 0),
                    det.get('bbox', {}).get('height', 0)
                ],
                'area': det.get('bbox', {}).get('width', 0) * det.get('bbox', {}).get('height', 0),
                'iscrowd': 0
            }
            for i, det in enumerate(detections)
        ]
    }

@app.route('/api/delete_file', methods=['DELETE'])
def delete_file():
    """åˆ é™¤æŒ‡å®šæ–‡ä»¶"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        filename = data.get('filename')
        
        if not session_id or not filename:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        if session_id not in session_data:
            return jsonify({'error': 'ä¼šè¯ä¸å­˜åœ¨'}), 404
        
        # æŸ¥æ‰¾å¹¶åˆ é™¤æ–‡ä»¶
        files = session_data[session_id]['files']
        file_to_delete = None
        file_index = -1
        
        for i, file_info in enumerate(files):
            if file_info['unique_filename'] == filename:
                file_to_delete = file_info
                file_index = i
                break
        
        if file_to_delete is None:
            return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        # åˆ é™¤ç‰©ç†æ–‡ä»¶
        filepath = file_to_delete['filepath']
        if os.path.exists(filepath):
            os.remove(filepath)
        
        # ä»ä¼šè¯æ•°æ®ä¸­ç§»é™¤
        files.pop(file_index)
        
        # æ¸…é™¤ç›¸å…³çš„é¢„æµ‹æ•°æ®
        predictions = session_data[session_id].get('predictions', {})
        if filename in predictions:
            del predictions[filename]
        
        logger.info(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {filename}")
        
        return jsonify({
            'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ',
            'remaining_files': len(files)
        })
        
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        return jsonify({'error': f'åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}'}), 500

@app.route('/api/extract_video_frames', methods=['POST'])
def extract_video_frames():
    """æå–è§†é¢‘å¸§"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        filename = data.get('filename')
        frame_interval = int(data.get('frame_interval', 1))  # å¸§é—´éš”
        
        if not session_id or not filename:
            return jsonify({'error': 'ç¼ºå°‘å¿…è¦å‚æ•°'}), 400
        
        if session_id not in session_data:
            return jsonify({'error': 'ä¼šè¯ä¸å­˜åœ¨'}), 404
        
        # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        video_file = None
        for file_info in session_data[session_id]['files']:
            if file_info['unique_filename'] == filename and file_info['type'] == 'video':
                video_file = file_info
                break
        
        if video_file is None:
            return jsonify({'error': 'è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨'}), 404
        
        video_path = video_file['filepath']
        
        # ä½¿ç”¨OpenCVæå–å¸§
        cap = cv2.VideoCapture(video_path)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        if total_frames == 0:
            cap.release()
            return jsonify({'error': 'æ— æ³•è¯»å–è§†é¢‘ä¿¡æ¯'}), 400
        
        # è®¡ç®—éœ€è¦æå–çš„å¸§æ•°
        extract_count = total_frames // frame_interval
        extracted_files = []
        
        frame_index = 0
        extracted_index = 0
        
        logger.info(f"å¼€å§‹æå–è§†é¢‘å¸§: {filename}, æ€»å¸§æ•°: {total_frames}, é—´éš”: {frame_interval}, é¢„è®¡æå–: {extract_count}")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # æŒ‰é—´éš”æå–å¸§
            if frame_index % frame_interval == 0:
                # ç”Ÿæˆå¸§æ–‡ä»¶å
                base_name = os.path.splitext(video_file['filename'])[0]
                frame_filename = f"{base_name}_frame_{extracted_index:04d}.jpg"
                frame_unique_filename = f"{session_id}_{frame_filename}"
                frame_filepath = os.path.join(UPLOAD_FOLDER, frame_unique_filename)
                
                # ä¿å­˜å¸§
                cv2.imwrite(frame_filepath, frame)
                
                # æ·»åŠ åˆ°æ–‡ä»¶åˆ—è¡¨
                frame_info = {
                    'filename': frame_filename,
                    'unique_filename': frame_unique_filename,
                    'filepath': frame_filepath,
                    'type': 'image',
                    'size': os.path.getsize(frame_filepath),
                    'timestamp': datetime.now().isoformat(),
                    'source_video': filename,
                    'frame_index': frame_index,
                    'time_seconds': frame_index / fps if fps > 0 else 0
                }
                
                extracted_files.append(frame_info)
                extracted_index += 1
            
            frame_index += 1
        
        cap.release()
        
        # å°†æå–çš„å¸§æ·»åŠ åˆ°ä¼šè¯æ•°æ®
        session_data[session_id]['files'].extend(extracted_files)
        
        logger.info(f"è§†é¢‘å¸§æå–å®Œæˆ: æå–äº† {len(extracted_files)} å¼ å›¾ç‰‡")
        
        return jsonify({
            'message': f'è§†é¢‘å¸§æå–å®Œæˆ',
            'total_frames': total_frames,
            'extracted_count': len(extracted_files),
            'frame_interval': frame_interval,
            'extracted_files': extracted_files  # è¿”å›æ‰€æœ‰æå–çš„æ–‡ä»¶ä¿¡æ¯
        })
        
    except Exception as e:
        logger.error(f"è§†é¢‘å¸§æå–å¤±è´¥: {e}")
        return jsonify({'error': f'è§†é¢‘å¸§æå–å¤±è´¥: {str(e)}'}), 500

@app.route('/api/clear_all_annotations', methods=['POST'])
def clear_all_annotations():
    """æ¸…é™¤æ‰€æœ‰æ ‡æ³¨æ•°æ®"""
    try:
        data = request.get_json()
        session_id = data.get('session_id')
        
        if not session_id:
            return jsonify({'error': 'ç¼ºå°‘ä¼šè¯ID'}), 400
        
        if session_id not in session_data:
            return jsonify({'error': 'ä¼šè¯ä¸å­˜åœ¨'}), 404
        
        # æ¸…é™¤æ‰€æœ‰é¢„æµ‹æ•°æ®
        if 'predictions' not in session_data[session_id]:
            session_data[session_id]['predictions'] = {}
        session_data[session_id]['predictions'] = {}
        
        logger.info(f"æ¸…é™¤æ‰€æœ‰æ ‡æ³¨æ•°æ®: {session_id}")
        
        return jsonify({'message': 'æ‰€æœ‰æ ‡æ³¨æ•°æ®å·²æ¸…é™¤'})
        
    except Exception as e:
        logger.error(f"æ¸…é™¤æ‰€æœ‰æ ‡æ³¨å¤±è´¥: {e}")
        return jsonify({'error': f'æ¸…é™¤æ‰€æœ‰æ ‡æ³¨å¤±è´¥: {str(e)}'}), 500

@app.route('/api/clear_session/<session_id>', methods=['DELETE'])
def clear_session(session_id: str):
    """æ¸…ç†ä¼šè¯æ•°æ®"""
    try:
        if session_id in session_data:
            # åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
            for file_info in session_data[session_id]['files']:
                filepath = file_info['filepath']
                if os.path.exists(filepath):
                    os.remove(filepath)
            
            # åˆ é™¤ä¼šè¯æ•°æ®
            del session_data[session_id]
            
            return jsonify({'message': 'ä¼šè¯æ¸…ç†å®Œæˆ'})
        else:
            return jsonify({'error': 'ä¼šè¯ä¸å­˜åœ¨'}), 404
            
    except Exception as e:
        logger.error(f"æ¸…ç†ä¼šè¯å¤±è´¥: {e}")
        return jsonify({'error': f'æ¸…ç†ä¼šè¯å¤±è´¥: {str(e)}'}), 500

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸš€ YOLOvæ™ºèƒ½æ ‡æ³¨å·¥å…·æœåŠ¡å™¨å¯åŠ¨ä¸­...")
    print("=" * 60)
    print(f"ğŸ“‚ ä¸Šä¼ æ–‡ä»¶å¤¹: {UPLOAD_FOLDER}")
    print(f"ğŸ§  æ¨¡å‹æ–‡ä»¶å¤¹: {MODELS_FOLDER}")
    print(f"ğŸ“Š ç»“æœæ–‡ä»¶å¤¹: {RESULTS_FOLDER}")
    print(f"ğŸ”§ è®¡ç®—è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    print("=" * 60)
    print("ğŸ“– ä½¿ç”¨è¯´æ˜:")
    print("1. åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ http://localhost:5000")
    print("2. ä¸Šä¼ æ‚¨çš„YOLOvæ¨¡å‹æ–‡ä»¶(.pt)")
    print("3. ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘è¿›è¡Œæ ‡æ³¨")
    print("4. è°ƒæ•´å‚æ•°å¹¶ç‚¹å‡»è‡ªåŠ¨æ ‡æ³¨")
    print("5. å¯¼å‡ºæ ‡æ³¨æ•°æ®ä¸ºè®­ç»ƒæ ¼å¼")
    print("=" * 60)
    
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(host='0.0.0.0', port=5000, debug=False)
